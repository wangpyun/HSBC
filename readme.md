# 算法设计文档

## 算法概述

本算法是一个基于LLM的，用于分析HTML/CSS的网页结构性相似度算法。本算法对网页结构数据分布不进行过多假设，采用数据驱动的方法，通过大规模真实网页结构数据的分布，学习到一个高效的相似度计算模型，以便于在实际应用中进行网页结构性相似度的计算。

## 算法原理

### 步骤1：数据搜集与处理

我们首先从互联网上搜集了大量的网页数据，并对这些网页数据进行了处理，提取出了网页的结构信息，包括HTML标签、属性、样式等。

### 步骤2：数据分析与建模

这一部分包含了算法的主要计算逻辑。主要分为以下几个步骤：
1. 特征提取：我们首先对网页结构数据进行“特征提取”，得到了一组特征向量。特征提取采用了一种基于LLM的方法，将网页结构数据映射到一个高维空间中，以便于后续的聚类分析和相似度计算。具体来说，我们将网页结构数据经过Few-shot以及CoT方法，获得一个可读性较高的文本总结。随后，对文本总结进行Embedding，得到特征向量。
2. 聚类分析：我们对特征向量进行聚类分析，得到了一个聚类模型，用于表示网页结构数据的分布情况。
3. 相似度计算：我们通过比较两个网页的特征向量在聚类模型中的位置，计算出它们的相似度。具体来说，可以通过每个网页的特征向量获取距离每个聚类中心的距离，然后通过一定的计算方法，得到网页之间的相似度。

### 步骤3：验证与优化

理解算法的有效性需要从多个角度进行验证。

1. 网页结构数据的特征向量的有效性：我们可以通过对特征向量进行可视化，来验证特征向量的有效性。具体来说，我们可以将特征向量映射到一个二维空间中，然后通过可视化工具，观察特征向量的分布情况。如果具有相似结构的网页在特征空间中的位置相近，那么说明特征向量的提取是有效的。并且，如果整体分布体现出一定的聚类特性，那么说明聚类分析也是有效的。

2. 算法端到端的有效性：我们可以通过一个带标签的数据集，具体来说，属于同一类别的网页，其彼此的相似度应该较高，而不同类别的网页，其相似度应该较低, 相关的metric可参考silhouette_score。我们可以通过这个数据集，来验证我们的算法是否能够正确地计算出网页之间的相似度。其中带标签的数据集可以手工制作，或者通过LLM进行合成。

## 算法理解

### 算法输入

待比较的两个网页的URL。

### 算法输出
1. 两个网页在聚类模型中的位置。即两个网页的特征向量与各聚类中心的距离。
2. 两个网页的相似度。即两个网页在聚类模型中的位置的相似度。比如，聚类模型中有三个聚类中心，分别为A、B、C，网页A与聚类中心A的距离为1，与聚类中心B的距离为1，与聚类中心C的距离为3；网页B与聚类中心A的距离为1，与聚类中心B的距离为1，与聚类中心C的距离为2。那么，网页A与网页B的相似度较高。

## 算法实现

我们采用了Python语言来实现该算法，并提供了相应的源代码。你可以在notebooks和src文件夹下找到所有代码。

data文件夹中包含了我们使用的网页urls，以及从这些urls中提取的网页结构数据，文本总结，以及特征向量。


## 使用方法

### 安装

创建一个新python环境，然后，可以通过以下命令安装所需的依赖：

```
pip install -r requirements.txt
```

### 运行

你可以通过以下命令来计算两个网页的相似性：

```
cd src
python main.py --urls your_url_a your_url_b
```

## 大规模应用优化方向

分布式计算：我们可以将算法进行分布式计算，将算法中的网页数据处理，文本摘要生成，以及Embedding，进行API化，并部署在一个分布式环境中（例如使用Docker容器， k8s集群等），以便于处理大规模的网页数据。

